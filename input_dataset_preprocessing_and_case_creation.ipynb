{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d32152a2-48d3-4d9f-a561-0582987ef2ca",
   "metadata": {},
   "source": [
    "## GPU Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c35c916b-7030-4314-84d8-0bc5311c4a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Name: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "CUDA Version: 12.0\n",
      "Number of GPUs: 1\n",
      "Current Device: 0\n",
      "Running matrix multiplication on GPU...\n",
      "Computation successful! Output shape: torch.Size([1000, 1000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "def check_cuda():\n",
    "    print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "        print(\"CUDA Version:\", torch.version.cuda)\n",
    "        print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "        print(\"Current Device:\", torch.cuda.current_device())\n",
    "    else:\n",
    "        print(\"CUDA is not available. Running on CPU.\")\n",
    "\n",
    "# Test simple computation on GPU\n",
    "def gpu_computation_test():\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"Skipping computation test as CUDA is not available.\")\n",
    "        return\n",
    "    \n",
    "    device = torch.device(\"cuda\")\n",
    "    A = torch.randn(1000, 1000, device=device)\n",
    "    B = torch.randn(1000, 1000, device=device)\n",
    "    \n",
    "    print(\"Running matrix multiplication on GPU...\")\n",
    "    C = torch.matmul(A, B)\n",
    "    print(\"Computation successful! Output shape:\", C.shape)\n",
    "    \n",
    "# Run the tests\n",
    "check_cuda()\n",
    "gpu_computation_test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e1d7db-f7f7-4f3f-bcf6-1dd54e960389",
   "metadata": {},
   "source": [
    "# Importing Dataset and Initial Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "193bf439-c562-4463-af98-6896d497a82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "051a65152ca34a27b9cff986db629fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_dataset.jsonl:  19%|#9        | 21.0M/110M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c141efc72394a288669f6e0e7b595de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val_dataset.jsonl:   0%|          | 0.00/11.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d90c082e8a9441d19d2ab8cb3f184bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_dataset.jsonl:   0%|          | 0.00/11.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ef96581a63487bb4997beb9bf55913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/23912 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e075ed2e9341599cac3a67b3d89cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/2986 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709fd0af974f41388881f6906b4824e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2990 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_dataset(\"gcelikmasat-work/BPMN-IT-Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb84c5de-81b7-443d-ae02-5d0994340999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'file_name', 'category', 'instruction', 'input', 'output'],\n",
      "    num_rows: 23912\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0ab0f8a-615e-458e-92d1-b4500ded9c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b77a9c1e-1de9-4e9b-9aca-a4e3f53ea838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>category</th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>accounts_receivable_process_0.gv</td>\n",
       "      <td>accounts_receivable_process</td>\n",
       "      <td>You are an expert in BPMN modeling and DOT lan...</td>\n",
       "      <td>\\n\\n\\nThe following description is about the a...</td>\n",
       "      <td>digraph accounts_receivable_process_0 {\\n\\tgra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>accounts_receivable_process_1.gv</td>\n",
       "      <td>accounts_receivable_process</td>\n",
       "      <td>You are an expert in BPMN modeling and DOT lan...</td>\n",
       "      <td>\\n\\n\\nThe text below is about the accounts rec...</td>\n",
       "      <td>digraph accounts_receivable_process_1 {\\n\\tgra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>accounts_receivable_process_10.gv</td>\n",
       "      <td>accounts_receivable_process</td>\n",
       "      <td>You are an expert in BPMN modeling and DOT lan...</td>\n",
       "      <td>\\n\\n\\nThe following text is about the accounts...</td>\n",
       "      <td>digraph accounts_receivable_process_10 {\\n\\tgr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>accounts_receivable_process_100.gv</td>\n",
       "      <td>accounts_receivable_process</td>\n",
       "      <td>You are an expert in BPMN modeling and DOT lan...</td>\n",
       "      <td>\\n\\n\\nThe following text is about the accounts...</td>\n",
       "      <td>digraph accounts_receivable_process_100 {\\n\\tg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>accounts_receivable_process_1000.gv</td>\n",
       "      <td>accounts_receivable_process</td>\n",
       "      <td>You are an expert in BPMN modeling and DOT lan...</td>\n",
       "      <td>\\n\\n\\nThe text below is about the accounts rec...</td>\n",
       "      <td>digraph accounts_receivable_process_1000 {\\n\\t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                            file_name                     category  \\\n",
       "0   0     accounts_receivable_process_0.gv  accounts_receivable_process   \n",
       "1   1     accounts_receivable_process_1.gv  accounts_receivable_process   \n",
       "2   2    accounts_receivable_process_10.gv  accounts_receivable_process   \n",
       "3   3   accounts_receivable_process_100.gv  accounts_receivable_process   \n",
       "4   4  accounts_receivable_process_1000.gv  accounts_receivable_process   \n",
       "\n",
       "                                         instruction  \\\n",
       "0  You are an expert in BPMN modeling and DOT lan...   \n",
       "1  You are an expert in BPMN modeling and DOT lan...   \n",
       "2  You are an expert in BPMN modeling and DOT lan...   \n",
       "3  You are an expert in BPMN modeling and DOT lan...   \n",
       "4  You are an expert in BPMN modeling and DOT lan...   \n",
       "\n",
       "                                               input  \\\n",
       "0  \\n\\n\\nThe following description is about the a...   \n",
       "1  \\n\\n\\nThe text below is about the accounts rec...   \n",
       "2  \\n\\n\\nThe following text is about the accounts...   \n",
       "3  \\n\\n\\nThe following text is about the accounts...   \n",
       "4  \\n\\n\\nThe text below is about the accounts rec...   \n",
       "\n",
       "                                              output  \n",
       "0  digraph accounts_receivable_process_0 {\\n\\tgra...  \n",
       "1  digraph accounts_receivable_process_1 {\\n\\tgra...  \n",
       "2  digraph accounts_receivable_process_10 {\\n\\tgr...  \n",
       "3  digraph accounts_receivable_process_100 {\\n\\tg...  \n",
       "4  digraph accounts_receivable_process_1000 {\\n\\t...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2a1b382-c094-46df-bd4d-bd58a725cd7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['accounts_receivable_process', 'account_payable_process',\n",
       "       'budget_preparation_process', 'churn_rate_prevention_process',\n",
       "       'client_onboarding_process_for_a_marketing_agency',\n",
       "       'content_promotion_process',\n",
       "       'customer_support_process_for_the_ticket_management',\n",
       "       'employee_onboarding_process', 'final_grades_submission_process',\n",
       "       'loan_application_process', 'order_fulfillment_process',\n",
       "       'process_for_optimizing_a_process', 'project_management_process',\n",
       "       'purchase_order_workflow',\n",
       "       'startup_due_diligence_for_a_venture_capitalist'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b738f500-7534-4f69-98b1-a39078c35205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c2d02a2-0c05-432e-99a5-07d6c304762d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "account_payable_process                               1600\n",
       "accounts_receivable_process                           1600\n",
       "budget_preparation_process                            1600\n",
       "churn_rate_prevention_process                         1570\n",
       "client_onboarding_process_for_a_marketing_agency      1600\n",
       "content_promotion_process                             1600\n",
       "customer_support_process_for_the_ticket_management    1600\n",
       "employee_onboarding_process                           1600\n",
       "final_grades_submission_process                       1600\n",
       "loan_application_process                              1600\n",
       "order_fulfillment_process                             1600\n",
       "process_for_optimizing_a_process                      1558\n",
       "project_management_process                            1600\n",
       "purchase_order_workflow                               1600\n",
       "startup_due_diligence_for_a_venture_capitalist        1584\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('category').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a472c8d-0ed0-420b-9a0e-80a9c6495ecf",
   "metadata": {},
   "source": [
    "# Explorative Preprocessing Attempt using Input Description Classifier (see 7.3)\n",
    "During the dataset preprocessing, it was assumed that specific labels in the textual descriptions would allow for more accurate User Stories and BDD scenarios during generation. As a result, the bpmn-information-extraction-v2 was applied, where the resulting columns would also be fed into the o3 model. However, trial-and-error found that the columns only lead to an increase in hallucination, and as a result, the columns would eventually be dropped, leaving only the input description and DOT outputs in the final cases. Due to the initial hypothesized use, the columns remain in the upcoming data cleaning steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2dc7fe-f5b2-4c21-966f-a7d76d229269",
   "metadata": {},
   "source": [
    "## Importing Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a0df823-12dd-4f34-89a2-1dc36ee0c6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"token-classification\", model=\"jtlicardo/bpmn-information-extraction-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc80463-dcd2-40d7-bd5d-39451099c145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tokens_from_row(row):\n",
    "    # Define the required classification labels\n",
    "    required_labels = ['B-TASK_INFO', 'I-TASK', 'O', 'B-TASK', 'I-PROCESS_INFO', 'B-PROCESS_INFO', 'I-TASK_INFO', 'I-AGENT', 'B-AGENT', 'I-CONDITION', 'B-CONDITION']\n",
    "\n",
    "    # Extract the text to be processed\n",
    "    text = row[\"input\"]\n",
    "    \n",
    "    # Use the token classification pipeline (assuming `pipe` is your model)\n",
    "    results = pipe(text)\n",
    "    \n",
    "    # Initialize a dictionary to store categorized tokens\n",
    "    categorized_tokens = {}\n",
    "\n",
    "    # Loop over the results of the pipeline and categorize tokens\n",
    "    for result in results:\n",
    "        entity = result[\"entity\"]\n",
    "        word = result[\"word\"]\n",
    "\n",
    "        # Remove subword tokens (e.g., ## prefixes from WordPiece)\n",
    "        word = word.replace(\"##\", \"\")\n",
    "\n",
    "        # If the entity is not already in the categorized_tokens dictionary, add it\n",
    "        if entity not in categorized_tokens:\n",
    "            categorized_tokens[entity] = []\n",
    "\n",
    "        # Append the word to the correct entity list\n",
    "        categorized_tokens[entity].append(word)\n",
    "\n",
    "    # Join words that belong to the same category\n",
    "    categorized_tokens = {k: \" \".join(v) for k, v in categorized_tokens.items()}\n",
    "\n",
    "    # Ensure all required classification labels exist in the final dictionary\n",
    "    for label in required_labels:\n",
    "        if label not in categorized_tokens:\n",
    "            categorized_tokens[label] = \"O\"  # Assign default value 'O' for missing labels\n",
    "\n",
    "    # Return the extracted token classifications\n",
    "    return categorized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeafd10-f444-454e-b289-a849647f0642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply token classification to the entire dataset without converting to pandas\n",
    "dataset = dataset.map(extract_tokens_from_row, batched=False, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6920558-b8bb-4ec0-b1bb-b1e9d21bc89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316d1295-2e2e-4cf1-bd95-9788d96fc9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d576fa-e61d-4991-a9ea-751d407d61fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.to_csv('train_dataset_modelv1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb01c5d7-4279-48ee-bad0-fc9b99922543",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603c31c3-5e48-41a1-95e6-2132e78523de",
   "metadata": {},
   "source": [
    "Firstly, the initial sentence is removed. This sentence simply reflected the format The following description is about {category}\". However, this category is not always reflective of the process, so the first sentence might throw off an LLM. Afterwards, we check what is left. Some scoping already highlighted that the second sentence is formatted to start with \"it\". Code is added to verify whether this is true on all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "570a59be-e6f7-4ef2-9a2f-b25f37d91aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do all rows' inputs start with 'it'? : True\n",
      "All rows start with 'it'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def remove_initial_sentence(text):\n",
    "    pattern = re.compile(r'^.*?\\.\\s*', re.DOTALL)\n",
    "    return pattern.sub('', text, count=1)\n",
    "\n",
    "# Function to extract the first word (lowercased) from a text.\n",
    "def get_first_word(text):\n",
    "    text = text.strip()\n",
    "    if text:\n",
    "        return text.split()[0].lower()\n",
    "    return None\n",
    "\n",
    "# Load the dataset (adjust the file path as necessary)\n",
    "df = pd.read_csv(\"train_dataset_modelv2.csv\")\n",
    "\n",
    "# Apply the function to remove the initial sentence from the 'input' column.\n",
    "df['input'] = df['input'].apply(remove_initial_sentence)\n",
    "\n",
    "# Extract the first word from the cleaned 'input'\n",
    "df['first_word'] = df['input'].apply(get_first_word)\n",
    "\n",
    "# Verify if all rows start with \"it\"\n",
    "all_start_with_it = df['first_word'].eq(\"it\").all()\n",
    "\n",
    "print(\"Do all rows' inputs start with 'it'? :\", all_start_with_it)\n",
    "\n",
    "# Print out a few rows that do NOT start with \"it\", if any.\n",
    "non_it_rows = df[df['first_word'] != \"it\"]\n",
    "if not non_it_rows.empty:\n",
    "    print(\"Rows not starting with 'it':\")\n",
    "    print(non_it_rows[['id', 'first_word', 'input']].head())\n",
    "else:\n",
    "    print(\"All rows start with 'it'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e0007c-b6d7-4ce8-986e-85911982752c",
   "metadata": {},
   "source": [
    "All rows start with 'it', so to remove ambiguity, \"it\" is replaced by \"the process\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5dca52a-6adf-4cf4-8028-3ff0f32195e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    The process starts with recording the buyer's ...\n",
      "1    The process begins when you record the buyer's...\n",
      "2    The process begins when you record the buyer's...\n",
      "3    The process starts with recording the buyer's ...\n",
      "4    The process starts with recording the buyer's ...\n",
      "Name: input, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def replace_initial_it(text):\n",
    "    # This regex matches \"it\" at the beginning of the text followed by a word boundary.\n",
    "    return re.sub(r'^(it)\\b', \"The process\", text, flags=re.IGNORECASE)\n",
    "\n",
    "# Replace the initial \"it\" with \"The process\"\n",
    "df['input'] = df['input'].apply(replace_initial_it)\n",
    "\n",
    "# Display a few examples to verify\n",
    "print(df['input'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a45d7dad-b108-4201-999c-afa0426572d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23912 entries, 0 to 23911\n",
      "Data columns (total 18 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   id              23912 non-null  int64 \n",
      " 1   file_name       23912 non-null  object\n",
      " 2   category        23912 non-null  object\n",
      " 3   instruction     23912 non-null  object\n",
      " 4   input           23912 non-null  object\n",
      " 5   output          23912 non-null  object\n",
      " 6   I-PROCESS_INFO  23912 non-null  object\n",
      " 7   B-TASK          23912 non-null  object\n",
      " 8   I-TASK          23912 non-null  object\n",
      " 9   B-TASK_INFO     23912 non-null  object\n",
      " 10  I-TASK_INFO     23912 non-null  object\n",
      " 11  B-PROCESS_INFO  23912 non-null  object\n",
      " 12  O               23912 non-null  object\n",
      " 13  I-AGENT         23912 non-null  object\n",
      " 14  B-AGENT         23912 non-null  object\n",
      " 15  I-CONDITION     23912 non-null  object\n",
      " 16  B-CONDITION     23912 non-null  object\n",
      " 17  first_word      23912 non-null  object\n",
      "dtypes: int64(1), object(17)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd6ad23-aee9-4d59-8d9b-fdd9ee6c3b82",
   "metadata": {},
   "source": [
    "Finally, the \"instruction\" column, the \"file_name\" column, \"O\" column and \"first_word\" columns are dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "785513dc-8a80-4362-baf4-d4ee957d1f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23912 entries, 0 to 23911\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   id              23912 non-null  int64 \n",
      " 1   category        23912 non-null  object\n",
      " 2   input           23912 non-null  object\n",
      " 3   output          23912 non-null  object\n",
      " 4   I-PROCESS_INFO  23912 non-null  object\n",
      " 5   B-TASK          23912 non-null  object\n",
      " 6   I-TASK          23912 non-null  object\n",
      " 7   B-TASK_INFO     23912 non-null  object\n",
      " 8   I-TASK_INFO     23912 non-null  object\n",
      " 9   B-PROCESS_INFO  23912 non-null  object\n",
      " 10  I-AGENT         23912 non-null  object\n",
      " 11  B-AGENT         23912 non-null  object\n",
      " 12  I-CONDITION     23912 non-null  object\n",
      " 13  B-CONDITION     23912 non-null  object\n",
      "dtypes: int64(1), object(13)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.drop([\"file_name\", \"instruction\", \"O\", \"first_word\"], axis=1, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be3ea88-95f2-4772-adcd-329e2fafd530",
   "metadata": {},
   "source": [
    "# Case Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f30787a9-2813-463b-a1f7-c7a83bc7cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping of categories to each overarching process\n",
    "financial_categories = [\n",
    "    \"accounts_receivable_process\",\n",
    "    \"account_payable_process\",\n",
    "    \"loan_application_process\",\n",
    "    \"purchase_order_workflow\",\n",
    "    \"order_fulfillment_process\",\n",
    "]\n",
    "\n",
    "marketing_categories = [\n",
    "    \"client_onboarding_process_for_a_marketing_agency\",\n",
    "    \"churn_rate_prevention_process\",\n",
    "    \"content_promotion_process\",\n",
    "    \"employee_onboarding_process\"\n",
    "]\n",
    "\n",
    "internal_categories = [\n",
    "    \"customer_support_process_for_the_ticket_management\",\n",
    "    \"process_for_optimizing_a_process\",\n",
    "    \"project_management_process\",\n",
    "]\n",
    "\n",
    "category_ranges = {\n",
    "    \"accounts_receivable_process\": (0, 1599),\n",
    "    \"account_payable_process\": (1600, 3199),\n",
    "    \"budget_preparation_process\": (3200, 4799),\n",
    "    \"churn_rate_prevention_process\": (4800, 6369),\n",
    "    \"client_onboarding_process_for_a_marketing_agency\": (6370, 7969),\n",
    "    \"content_promotion_process\": (7970, 9569),\n",
    "    \"customer_support_process_for_the_ticket_management\": (9570, 11169),\n",
    "    \"employee_onboarding_process\": (11170, 12769),\n",
    "    \"final_grades_submission_process\": (12770, 14369),\n",
    "    \"loan_application_process\": (14370, 15969),\n",
    "    \"order_fulfillment_process\": (15970, 17569),\n",
    "    \"process_for_optimizing_a_process\": (17570, 19127),\n",
    "    \"project_management_process\": (19128, 20727),\n",
    "    \"purchase_order_workflow\": (20728, 22327),\n",
    "    \"startup_due_diligence_for_a_venture_capitalist\": (22328, 23927)  # or the final range\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1842b72-f3d5-4ff4-877b-c3e75376e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_alternating_df(master_df, category_ranges, categories):\n",
    "    \"\"\"\n",
    "    Create a new DataFrame where rows alternate from each category.\n",
    "    For each \"case\" (i.e. the i-th row within each category slice),\n",
    "    the output will include one row from each category (in the order provided).\n",
    "    \"\"\"\n",
    "    # Determine the number of rows (cases) available per category:\n",
    "    num_rows_per_category = {}\n",
    "    for cat in categories:\n",
    "        start, end = category_ranges[cat]\n",
    "        num_rows_per_category[cat] = end - start + 1\n",
    "    # Use the minimum number of rows across categories to ensure alignment\n",
    "    min_cases = min(num_rows_per_category.values())\n",
    "    \n",
    "    # Build a list of rows in alternating order\n",
    "    rows = []\n",
    "    for i in range(min_cases):\n",
    "        for cat in categories:\n",
    "            start, _ = category_ranges[cat]\n",
    "            global_idx = start + i\n",
    "            row = master_df.iloc[global_idx].copy()\n",
    "            # Add columns to indicate the original category and the case number\n",
    "            row['source_category'] = cat\n",
    "            row['case'] = i\n",
    "            rows.append(row)\n",
    "    \n",
    "    # Create a DataFrame from the list of rows\n",
    "    alternating_df = pd.DataFrame(rows)\n",
    "    # Optionally, reset index\n",
    "    alternating_df.reset_index(drop=True, inplace=True)\n",
    "    return alternating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98fdb5e3-c205-4e38-991b-738e7c174081",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_financial = create_alternating_df(df, category_ranges, financial_categories)\n",
    "df_marketing = create_alternating_df(df, category_ranges, marketing_categories)\n",
    "df_internal = create_alternating_df(df, category_ranges, internal_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c45031e7-82c7-4e40-b75f-59f7d1c77ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>category</th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>source_category</th>\n",
       "      <th>case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6370</td>\n",
       "      <td>client_onboarding_process_for_a_marketing_agen...</td>\n",
       "      <td>client_onboarding_process_for_a_marketing_agency</td>\n",
       "      <td>You are an expert in BPMN modeling and DOT lan...</td>\n",
       "      <td>\\n\\n\\nThe following description is about the c...</td>\n",
       "      <td>digraph client_onboarding_process_for_a_market...</td>\n",
       "      <td>client_onboarding_process_for_a_marketing_agency</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4800</td>\n",
       "      <td>churn_rate_prevention_process_0.gv</td>\n",
       "      <td>churn_rate_prevention_process</td>\n",
       "      <td>You are an expert in BPMN modeling and DOT lan...</td>\n",
       "      <td>\\n\\n\\nThe following description is about the c...</td>\n",
       "      <td>digraph churn_rate_prevention_process_0 {\\n\\tg...</td>\n",
       "      <td>churn_rate_prevention_process</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7970</td>\n",
       "      <td>content_promotion_process_0.gv</td>\n",
       "      <td>content_promotion_process</td>\n",
       "      <td>You are an expert in BPMN modeling and DOT lan...</td>\n",
       "      <td>\\n\\n\\nThe following text is about the content ...</td>\n",
       "      <td>digraph content_promotion_process_0 {\\n\\tgraph...</td>\n",
       "      <td>content_promotion_process</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11170</td>\n",
       "      <td>employee_onboarding_process_0.gv</td>\n",
       "      <td>employee_onboarding_process</td>\n",
       "      <td>You are an expert in BPMN modeling and DOT lan...</td>\n",
       "      <td>\\n\\n\\nThe text below is about the employee onb...</td>\n",
       "      <td>digraph employee_onboarding_process_0 {\\n\\tgra...</td>\n",
       "      <td>employee_onboarding_process</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6371</td>\n",
       "      <td>client_onboarding_process_for_a_marketing_agen...</td>\n",
       "      <td>client_onboarding_process_for_a_marketing_agency</td>\n",
       "      <td>You are an expert in BPMN modeling and DOT lan...</td>\n",
       "      <td>\\n\\n\\nThe following description is about the c...</td>\n",
       "      <td>digraph client_onboarding_process_for_a_market...</td>\n",
       "      <td>client_onboarding_process_for_a_marketing_agency</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                          file_name  \\\n",
       "0   6370  client_onboarding_process_for_a_marketing_agen...   \n",
       "1   4800                 churn_rate_prevention_process_0.gv   \n",
       "2   7970                     content_promotion_process_0.gv   \n",
       "3  11170                   employee_onboarding_process_0.gv   \n",
       "4   6371  client_onboarding_process_for_a_marketing_agen...   \n",
       "\n",
       "                                           category  \\\n",
       "0  client_onboarding_process_for_a_marketing_agency   \n",
       "1                     churn_rate_prevention_process   \n",
       "2                         content_promotion_process   \n",
       "3                       employee_onboarding_process   \n",
       "4  client_onboarding_process_for_a_marketing_agency   \n",
       "\n",
       "                                         instruction  \\\n",
       "0  You are an expert in BPMN modeling and DOT lan...   \n",
       "1  You are an expert in BPMN modeling and DOT lan...   \n",
       "2  You are an expert in BPMN modeling and DOT lan...   \n",
       "3  You are an expert in BPMN modeling and DOT lan...   \n",
       "4  You are an expert in BPMN modeling and DOT lan...   \n",
       "\n",
       "                                               input  \\\n",
       "0  \\n\\n\\nThe following description is about the c...   \n",
       "1  \\n\\n\\nThe following description is about the c...   \n",
       "2  \\n\\n\\nThe following text is about the content ...   \n",
       "3  \\n\\n\\nThe text below is about the employee onb...   \n",
       "4  \\n\\n\\nThe following description is about the c...   \n",
       "\n",
       "                                              output  \\\n",
       "0  digraph client_onboarding_process_for_a_market...   \n",
       "1  digraph churn_rate_prevention_process_0 {\\n\\tg...   \n",
       "2  digraph content_promotion_process_0 {\\n\\tgraph...   \n",
       "3  digraph employee_onboarding_process_0 {\\n\\tgra...   \n",
       "4  digraph client_onboarding_process_for_a_market...   \n",
       "\n",
       "                                    source_category  case  \n",
       "0  client_onboarding_process_for_a_marketing_agency     0  \n",
       "1                     churn_rate_prevention_process     0  \n",
       "2                         content_promotion_process     0  \n",
       "3                       employee_onboarding_process     0  \n",
       "4  client_onboarding_process_for_a_marketing_agency     1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_marketing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9146261f-433a-4523-b810-07191cadd4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 6280\n",
       "file_name          6280\n",
       "category           6280\n",
       "instruction        6280\n",
       "input              6280\n",
       "output             6280\n",
       "source_category    6280\n",
       "case               6280\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_marketing.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af457d46-20f9-400a-9f6d-1a0bdb87a11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570.0\n"
     ]
    }
   ],
   "source": [
    "print(6280/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aeef5da4-584c-450b-8948-1f616da51634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 8000\n",
       "file_name          8000\n",
       "category           8000\n",
       "instruction        8000\n",
       "input              8000\n",
       "output             8000\n",
       "source_category    8000\n",
       "case               8000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_financial.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "211602f7-0b76-42e3-851b-b1978878c69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600.0\n"
     ]
    }
   ],
   "source": [
    "print(8000/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f9da47e-a675-423b-af19-50f8fdcad181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 4674\n",
       "file_name          4674\n",
       "category           4674\n",
       "instruction        4674\n",
       "input              4674\n",
       "output             4674\n",
       "source_category    4674\n",
       "case               4674\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_internal.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "496d0cab-1973-4986-975b-299806db1c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1558.0\n"
     ]
    }
   ],
   "source": [
    "print(4674/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f89d678e-0193-42e8-aeb6-5fb620b51414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Map dataset names to tuple sizes\n",
    "datasets = {\n",
    "    \"Financial_Transactions_&_Procurement\": (df_financial, 5),\n",
    "    \"Customer_Engagement_&_Marketing\": (df_marketing, 4),\n",
    "    \"Internal_Operations_&_Process_Management\": (df_internal, 3),\n",
    "}\n",
    "\n",
    "# Create export directory\n",
    "export_dir = \"tuple_prompts\"\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "# Loop over each dataset, grouping rows into tuples.\n",
    "for name, (df_cat, tuple_size) in datasets.items():\n",
    "    num_tuples = len(df_cat) // tuple_size\n",
    "    for i in range(num_tuples):\n",
    "        # Get the current tuple of rows (they are arranged in alternating order)\n",
    "        rows = df_cat.iloc[i * tuple_size : (i + 1) * tuple_size]\n",
    "        \n",
    "        # Build prompt text header\n",
    "        prompt_text = f\"### {name.replace('_', ' ')} — Tuple {i+1}\\n\\n\"\n",
    "        for j, (_, row) in enumerate(rows.iterrows()):\n",
    "            prompt_text += f\"---\\nProcess {j+1}\\n\"\n",
    "            prompt_text += f\"Input:\\n{row['input']}\\n\\n\"\n",
    "            prompt_text += f\"Output:\\n{row['output']}\\n\\n\"\n",
    "        \n",
    "        # Write the prompt text to a .txt file\n",
    "        filename = f\"{name}_tuple_{i+1}.txt\"\n",
    "        filepath = os.path.join(export_dir, filename)\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f27d6b0-b87b-4f8b-9986-e39c17d998b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jorick/tuple_prompts_zip.zip'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Example: Zip a folder\n",
    "folder_to_zip = 'tuple_prompts'  \n",
    "output_filename = 'tuple_prompts_zip' \n",
    "\n",
    "shutil.make_archive(output_filename, 'zip', folder_to_zip)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
